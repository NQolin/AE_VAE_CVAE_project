# AE_VAE_CVAE_project
Проект посвящен использованию стандартного, вариационного и условного вариационного автоэнкодеров, обученных на LFW (Labeled Faces in the Wild) и MNIST



- **Классический Autoencoder (AE)** — для реконструкции изображений и изменения признаков (например, улыбки).
- **Variational Autoencoder (VAE)** — для генерации новых изображений цифр и анализа латентного пространства.
- **Conditional VAE (CVAE)** — для генерации изображений цифр заданного класса.

---

## Состав проекта

---

## 1 Классический Autoencoder (AE) на LFW

- Используются изображения лиц (датасет LFW) и атрибуты (например, «улыбка»).
- Модель обучается восстанавливать лицо из сжатого латентного представления.
- Архитектура: Conv2D → Linear (латентный вектор) → ConvTranspose2D.
- Через сэмплирование случайных латентных векторов получается генерация новых лиц.
- Выражение "грусти" заменяется на "улыбку" путём сдвига в латентном пространстве.

---

## 2 Variational Autoencoder (VAE) на MNIST


- Используются изображениях цифр (MNIST).
- Энкодер выводит параметры распределения (μ, σ) → сэмплируется латентный вектор `z`.
- Декодер генерирует изображение из `z`.
- Генерация цифр из случайного шума `z ~ N(0,1)`.
- t-SNE визуализация латентных векторов для анализа структуры пространства.
-
   **Функция потерь:**
- Binary Cross Entropy (BCE) — реконструкция.
- KL-дивергенция — приближение к N(0,1).



---

## 3 Conditional VAE (CVAE) на MNIST

- Модификация VAE, где учитывается класс (цифра от 0 до 9).
- На вход декодеру подаётся `[z; y]`, где `y` — one-hot код класса.

- Генерация цифр нужного класса: можно «задать» цифру и получить её изображение.
- Визуализация латентного пространства: как классы распределяются при наличии меток.
- 
   **Функция потерь:**
- Такая же, как у VAE: BCE + KL-дивергенция.


```bash
pip install torch torchvision matplotlib scikit-learn numpy pandas scikit-image

